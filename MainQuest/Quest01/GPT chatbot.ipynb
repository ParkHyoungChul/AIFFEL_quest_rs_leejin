{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65326f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chatbot_data = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "chatbot = pd.read_csv(path_to_chatbot_data)\n",
    "chatbot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a708c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68148883",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d361f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.strip() # 입력받은 sentence의 양쪽 공백을 제거\n",
    " \n",
    "    sentence = re.sub(r\"([.!?;~])+\", r\"\\1\", sentence)   # 연속된 구두점들을 하나의 구두점으로 변환\n",
    "    sentence = re.sub(r\"([?.!,;~])\", r\" \\1 \", sentence) # 단어와 구두점 사이의 거리 추가 (토커나이저가 공백을 기준으로 단어를 분리하기에, 단어와 구두점이 붙어있음에 따른 의미 손실을 방지)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)         # 연속된 공백을 하나의 공백으로 축소\n",
    "    \n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\", \";\", \"~\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^가-힣0-9a-zA-Z.?!,;~]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()  # 새로 추가됐을 수 있는 문장 양쪽의 공백을 제거\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations(df):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    questions = df['Q']\n",
    "    for line in questions:\n",
    "        inputs.append(preprocess_sentence(line))\n",
    "\n",
    "    answers = df['A']\n",
    "    for line in answers:\n",
    "        outputs.append(preprocess_sentence(line))    \n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c784fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = load_conversations(chatbot)\n",
    "\n",
    "# TensorFlow 데이터셋으로 변환\n",
    "dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    \"encoder_inputs\": questions,\n",
    "    \"outputs\": answers\n",
    "})\n",
    "\n",
    "# 필요한 경우 map 함수 적용\n",
    "dataset = dataset.map(lambda x: ({\"encoder_inputs\": x[\"encoder_inputs\"]}, {\"outputs\": x[\"outputs\"]}))\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164642f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81eff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46927375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "vocab_size = tokenizer.vocab_size + 2\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot['Q_processed'] = chatbot['Q'].apply(preprocess_sentence)\n",
    "chatbot['A_processed'] = chatbot['A'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot['Q_length'] = chatbot['Q_processed'].apply(lambda x: len(x.split()))\n",
    "chatbot['A_length'] = chatbot['A_processed'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d738ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q_length = chatbot['Q_length'].max()\n",
    "max_a_length = chatbot['A_length'].max()\n",
    "mean_q_length = chatbot['Q_length'].mean()\n",
    "mean_a_length = chatbot['A_length'].mean()\n",
    "\n",
    "print(f'Max Question Length: {max_q_length}, Mean Question Length: {mean_q_length}')\n",
    "print(f'Max Answer Length: {max_a_length}, Mean Answer Length: {mean_a_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10879b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(chatbot['Q_length'], bins=30, alpha=0.5, label='Question Lengths')\n",
    "plt.hist(chatbot['A_length'], bins=30, alpha=0.5, label='Answer Lengths')\n",
    "plt.xlabel('Length (number of tokens)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Question and Answer Lengths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94359d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 15\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29315ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 15 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 15으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='pre')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='pre')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(vocab_size))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb972e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 강요\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # START_TOKEN 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:] # END_TOKEN 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745af978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "    \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9495a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378340f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_decoder_layer(units, d_model, num_heads, dropout, name=\"gpt_decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어: 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어: 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention1)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention1)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, look_ahead_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34674bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"gpt_decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩 추가\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = gpt_decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"gpt_decoder_layer_{}\".format(i),\n",
    "        )(inputs=[outputs, look_ahead_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, look_ahead_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_model(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"gpt_model\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # Look-ahead Mask 생성\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(inputs)\n",
    "\n",
    "    # GPT-1 디코더 적용\n",
    "    decoder_outputs = gpt_decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )(inputs=[inputs, look_ahead_mask])\n",
    "\n",
    "    # 출력 레이어 (단어 분포를 반환)\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size)(decoder_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "344b0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gpt_decoder (Functional)        (None, None, 512)    7333888     inputs[0][0]                     \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, None, 8160)   4186080     gpt_decoder[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 11,519,968\n",
      "Trainable params: 11,519,968\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = gpt_model(\n",
    "    vocab_size=vocab_size,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "29b851b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "684b24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 된 학습률(Learning rate)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000 * 5):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1bd9ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e5bfe021",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b01be8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:582: UserWarning: Input dict contained keys ['dec_inputs'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:180 __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:56 _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:649 map_to_output_names\n        raise ValueError('Found unexpected keys that do not correspond '\n\n    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['outputs']). Expected: ['dense_12']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1122135085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:180 __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:56 _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:649 map_to_output_names\n        raise ValueError('Found unexpected keys that do not correspond '\n\n    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['outputs']). Expected: ['dense_12']\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8911b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
