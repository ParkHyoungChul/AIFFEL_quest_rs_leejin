{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1683a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad1bd0",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e7bceed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "16c85c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수 \n",
    "def load_conversations():\n",
    "    # 데이터 경로\n",
    "    path_to_chatbot_data = 'aiffel/transformer_chatbot/data'\n",
    "    \n",
    "    # CSV 파일을 읽고 질문과 답변을 각각 추출\n",
    "    data = pd.read_csv(path_to_chatbot_data)\n",
    "\n",
    "    inputs = data['Q'].tolist()  # 질문 (Q) 컬럼\n",
    "    outputs = data['A'].tolist()  # 답변 (A) 컬럼\n",
    "    \n",
    "    # MAX_SAMPLES만큼 데이터를 자름\n",
    "    if len(inputs) > MAX_SAMPLES:\n",
    "        inputs = inputs[:MAX_SAMPLES]\n",
    "        outputs = outputs[:MAX_SAMPLES]\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "78a31051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일을 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "path_to_chatbot_data = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData.csv'\n",
    "\n",
    "if os.path.exists(path_to_chatbot_data):\n",
    "    print(\"파일이 존재합니다.\")\n",
    "else:\n",
    "    print(\"파일을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d32fbf4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'aiffel/transformer_chatbot/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82/104050531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_conversations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"첫 번째 질문: {inputs[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"첫 번째 답변: {outputs[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_82/2878946339.py\u001b[0m in \u001b[0;36mload_conversations\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# CSV 파일을 읽고 질문과 답변을 각각 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_chatbot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 질문 (Q) 컬럼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aiffel/transformer_chatbot/data'"
     ]
    }
   ],
   "source": [
    "inputs, outputs = load_conversations()\n",
    "print(f\"첫 번째 질문: {inputs[0]}\")\n",
    "print(f\"첫 번째 답변: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25105467",
   "metadata": {},
   "source": [
    "띄어쓰기 때문에 오류가 발생했네요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "87193f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_chatbot_data = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "chatbot = pd.read_csv(path_to_chatbot_data)\n",
    "chatbot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "0d27459f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "01bd0564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5290</td>\n",
       "      <td>5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3570</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2963</td>\n",
       "      <td>2963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Q     A\n",
       "label            \n",
       "0      5290  5290\n",
       "1      3570  3570\n",
       "2      2963  2963"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba723b01",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "e67ee1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    sentence = re.sub(r'[^\\w\\W\\.\\?!,]', \"\", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (영어, 한글, 숫자, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|?.!,0-9]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "3fa8e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations(df):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    questions = df['Q']\n",
    "    for line in questions:\n",
    "        inputs.append(preprocess_sentence(line))\n",
    "\n",
    "    answers = df['A']\n",
    "    for line in answers:\n",
    "        outputs.append(preprocess_sentence(line))    \n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "919cc236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요.\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations(chatbot)\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "741561f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "a9cca4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "ad135ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8168]\n",
      "END_TOKEN의 번호 : [8169]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "7d84f5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8170\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "8945e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5756, 607, 2488, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2354, 7507, 5, 6270, 94, 7958]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "092be2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot['Q_processed'] = chatbot['Q'].apply(preprocess_sentence)\n",
    "chatbot['A_processed'] = chatbot['A'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "677a076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot['Q_length'] = chatbot['Q_processed'].apply(lambda x: len(x.split()))\n",
    "chatbot['A_length'] = chatbot['A_processed'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "bdc850d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Question Length: 15, Mean Question Length: 3.5885139135583186\n",
      "Max Answer Length: 21, Mean Answer Length: 3.694070878795568\n"
     ]
    }
   ],
   "source": [
    "max_q_length = chatbot['Q_length'].max()\n",
    "max_a_length = chatbot['A_length'].max()\n",
    "mean_q_length = chatbot['Q_length'].mean()\n",
    "mean_a_length = chatbot['A_length'].mean()\n",
    "\n",
    "print(f'Max Question Length: {max_q_length}, Mean Question Length: {mean_q_length}')\n",
    "print(f'Max Answer Length: {max_a_length}, Mean Answer Length: {mean_a_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "20b5de83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(chatbot['Q_length'], bins=30, alpha=0.5, label='Question Lengths')\n",
    "plt.hist(chatbot['A_length'], bins=30, alpha=0.5, label='Answer Lengths')\n",
    "plt.xlabel('Length (number of tokens)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Question and Answer Lengths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "c6434595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 15\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "e105742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='pre')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='pre')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "5022ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8170\n",
      "필터링 후의 질문 샘플 개수: 11571\n",
      "필터링 후의 답변 샘플 개수: 11571\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "ade9d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 강요\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # START_TOKEN 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:] # END_TOKEN 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf7ff3",
   "metadata": {},
   "source": [
    "### 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "00276455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "2fc90523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "5f188a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "    \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ece45a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b3b69ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "    \n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "9aee9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "b0a9faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "        'query': attention1,\n",
    "        'key': enc_outputs,\n",
    "        'value': enc_outputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "264ebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "de59a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "1ee38a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3145728     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3673088     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8170)   2099690     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,918,506\n",
      "Trainable params: 8,918,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "335031dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "b94c10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 된 학습률(Learning rate)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=8000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "7fb9d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwa0lEQVR4nO3deXycZbn/8c+VfV+apnvThbaUshbKpixqUUCUouKhHBcUlKOCy+Fs8FM5HH7yO3I8isvBBQ8o8kIBFQ9BUGRHPNhSttJSSkNL9yVt006afbl+fzxP0mnIJJNknkmTfN+v17zyzD3Pcz/XTJK55l7mfszdERERSbWM4Q5ARERGJyUYERGJhBKMiIhEQglGREQioQQjIiKRyBruAIbT+PHjfebMmcMdhojIiPLCCy/sdvfK/vYb0wlm5syZrFixYrjDEBEZUcxsYzL7qYtMREQioQQjIiKRUIIREZFIRJpgzOw8M1trZjVmdm0vj+ea2b3h48vMbGbcY9eF5WvN7Ny48jvMbJeZrepR1zgze9TM1oU/y6N8biIi0rfIEoyZZQK3AucDC4BLzWxBj92uAOrcfQ5wC3BzeOwCYClwNHAe8MOwPoCfh2U9XQs87u5zgcfD+yIiMkyibMGcAtS4+3p3bwXuAZb02GcJcGe4/RtgsZlZWH6Pu7e4+wagJqwPd38G2NvL+eLruhO4KIXPRUREBijKBDMV2Bx3f0tY1us+7t4O7Acqkjy2p4nuvj3c3gFM7G0nM7vSzFaY2Yra2tpknoeIiAzCqBzk9+AaBL1eh8Ddb3P3Re6+qLKy3+8JpcTWfU08vmZnWs4lInK4iDLBbAWmx92fFpb1uo+ZZQGlwJ4kj+1pp5lNDuuaDOwadOQpdslPnuOKO1fQ1tE53KGIiKRNlAnmeWCumc0ysxyCQfvqHvtUA5eF2xcDT4Stj2pgaTjLbBYwF1jez/ni67oMeCAFzyEltu5rAmBb+FNEZCyILMGEYypXA48Aa4D73H21md1oZheGu90OVJhZDXAN4cwvd18N3Ae8BvwRuMrdOwDM7FfAc8CRZrbFzK4I6/om8F4zWwecE94/LJQX5ACwcU/jMEciIpI+ka5F5u4PAw/3KLs+brsZ+GiCY28Cbuql/NIE++8BFg8l3qiUFWSzt6GVTXuVYERk7BiVg/yHm/zs4Cs8SjAiMpYowaTBgZZ2ADapi0xExhAlmDSINbUBsFEtGBEZQ5RgIubuxJq7WjANBJPkRERGPyWYiDW1ddDR6UwqyaOhtYO9Da3DHZKISFoowUQs1hS0Xo6ZWgqom0xExg4lmIjFmoPxl2OmlgCwWQlGRMYIJZiIdQ3wL5hcghls2N0wzBGJiKSHEkzEulowE0rymFqWz5u1SjAiMjYowUSsPpxBVpKXxZwJRby568AwRyQikh5KMBHr6iIrzsvmiMoi1u8+QGenpiqLyOinBBOxru/AFIctmOa2zu7VlUVERjMlmIjFmtrIzcogLzuTOROKAKipVTeZiIx+SjARizW3U5KfDcARlUGC0TiMiIwFSjARizW3UZwXXBVhXGEO4wpzeFMtGBEZA5RgIhZraqMkL7v7/hGVhby5S1OVRWT0U4KJWHwXGcCcCUWs21WvRS9FZNRTgolYfXMbJXkHLxw6b2IxdY1t1Na3DGNUIiLRU4KJWKzp0BbMUZODNcle2x4brpBERNJCCSZi8YP8cDDBrNleP1whiYikhRJMhJrbOmht7zxkkL80P5upZflqwYjIqKcEE6HudcjiusggaMWsUYIRkVFOCSZCXSspxw/yAyyYXMz62gM0t3UMR1giImmhBBOhroUu47vIABZMKaHT4Y2dGocRkdFLCSZCse4uskNbMN0zybapm0xERi8lmAglasFMLy+gODeLVdv2D0dYIiJpoQQToUSD/BkZxrHTSnllsxKMiIxeSjAR6hrkL+4xyA9w/PQy1myPaaBfREYtJZgIxZrayMow8rMz3/bYCdPLaO90VmscRkRGKSWYCMWa2yjJz8bM3vbYwullALy8eV96gxIRSRMlmAjVN7e/7TswXSaU5DG5NE8JRkRGrUgTjJmdZ2ZrzazGzK7t5fFcM7s3fHyZmc2Me+y6sHytmZ3bX51mttjMXjSzl83sWTObE+VzS0asqY3iHjPI4p0wvYxXlGBEZJSKLMGYWSZwK3A+sAC41MwW9NjtCqDO3ecAtwA3h8cuAJYCRwPnAT80s8x+6vwR8DF3PwH4JfC1qJ5bsoJrwfTegoFgoH/T3kb2HNDS/SIy+kTZgjkFqHH39e7eCtwDLOmxzxLgznD7N8BiCwYslgD3uHuLu28AasL6+qrTgZJwuxTYFtHzSlrPq1n2dGJVOQAvbKxLV0giImkTZYKZCmyOu78lLOt1H3dvB/YDFX0c21ednwEeNrMtwCeAb/YWlJldaWYrzGxFbW3tIJ5W8oIxmMQJ5rhppeRkZbBsw95I4xARGQ6jaZD/74H3u/s04GfAd3rbyd1vc/dF7r6osrIy0oCCWWSJu8jysjNZOL2M5UowIjIKRZlgtgLT4+5PC8t63cfMsgi6tvb0cWyv5WZWCRzv7svC8nuBd6TmaQxOW0cnja0dfQ7yA5w6u4LV2/Z3fylTRGS0iDLBPA/MNbNZZpZDMGhf3WOfauCycPti4Al397B8aTjLbBYwF1jeR511QKmZzQvrei+wJsLn1q/uZWISTFPucuqscXS6xmFEZPTp+91vCNy93cyuBh4BMoE73H21md0IrHD3auB24C4zqwH2EiQMwv3uA14D2oGr3L0DoLc6w/LPAr81s06ChHN5VM8tGfVd14LJ77sFc2JVOdmZxrL1e3n3kRPSEZqISFpElmAA3P1h4OEeZdfHbTcDH01w7E3ATcnUGZb/DvjdEENOmVhTVwum7wSTn5PJcdPKWLZhTzrCEhFJm9E0yH9Y6Wuhy55On13Byi0ahxGR0UUJJiLd14Lpp4sM4My54+nodP63Rq0YERk9lGAiEktyDAbgxBnlFOVm8fQb0X4vR0QknZRgIpLsLDKA7MwM3nFEBc+8UUswiU5EZORTgolIrKkNMyjMSW4exdlHVrJ1XxNv1jZEHJmISHoowUQk1txOcW4WGRlvvxZMb86aG6wqoG4yERktlGAiEmtqS2r8pcv0cQXMrizkqbW7IoxKRCR9lGAiEutnocvenHPURP66fo+mK4vIqKAEE5FYc1tS34GJd+7RE2nrcJ58Xa0YERn5lGAiMtAuMoCF08upLM7lkdU7IopKRCR9lGAi0t+1YHqTkWG8d8FEnlpbS3NbR0SRiYikhxJMRPq7Fkwi5x09icbWDp5dtzuCqERE0kcJJgKdnc6BloG3YABOm11BcV4WD6/aHkFkIiLpowQTgfqWdtyTW+iyp5ysDM4/ZhJ/Wr2TplZ1k4nIyKUEE4GBLHTZm4sWTuVASzuPrdmZyrBERNJKCSYCB9chG1yCOW1WBZNK8vifl3peYVpEZORQgonAwZWUB3c9t4wMY8kJU3j6jVr2NrSmMjQRkbRRgolAdxfZIFswEHSTtXc6v1+5LVVhiYiklRJMBGJD7CIDOGpyCfMnFfPrFVtSFZaISFopwUTg4CD/4LrIuvztqVW8unU/K7fsS0FUIiLppQQTga5B/qLcoSWYixZOJT87k18u25SKsERE0koJJgKx5jYKczLJyhzay1uSl82Fx0/hgZe3aYVlERlxlGAiMJiFLhP52GlVNLV1aMqyiIw4/SYYM5tnZo+b2arw/nFm9rXoQxu5Ys1tQxrgj3fctDKOnVrKL57bSGenp6ROEZF0SKYF81PgOqANwN1XAkujDGqkq29uH/IAf7zLz5hJza4DupyyiIwoySSYAndf3qOsPYpgRovgYmOpacEAfOC4KUwqyeO2Z9anrE4Rkaglk2B2m9kRgAOY2cWAlvrtQ6ypnZJBLHSZSHZmBpefMZPn1u9h1db9KatXRCRKySSYq4CfAPPNbCvwFeBzUQY10gXXgkldCwZg6SlVFOVmqRUjIiNGMgnG3f0coBKY7+5nJHncmOTug7qaZX9K8rL521Or+P3KbayvPZDSukVEopBMovgtgLs3uHt9WPab6EIa2RpbO+jo9JQO8ne58qzZ5GZl8v3H16W8bhGRVEv4Lmhm84GjgVIz+3DcQyVAXtSBjVRdX4hM5SB/l/FFuXzyHTO47Zn1XP2eOcyZUJzyc4iIpEpfLZgjgQ8AZcAH424nAp9NpnIzO8/M1ppZjZld28vjuWZ2b/j4MjObGffYdWH5WjM7t786LXCTmb1hZmvM7EvJxJhqsaahL3TZl7876wjyszP53uM1kdQvIpIqCVsw7v4A8ICZne7uzw20YjPLBG4F3gtsAZ43s2p3fy1utyuAOnefY2ZLgZuBS8xsAcF3bY4GpgCPmdm88JhEdX4KmE4wTtRpZhMGGnMq1A/xWjD9GVeYw6feMZMfPf0mnz/7CBZMKYnkPCIiQ5XMGMxLZnaVmf3QzO7ouiVx3ClAjbuvd/dW4B5gSY99lgB3htu/ARabmYXl97h7i7tvAGrC+vqq8/PAje7eCeDuu5KIMeW6LzYWUQsGglZMaX42Nz38Gu76dr+IHJ6SSTB3AZOAc4GngWlAfZ9HBKYCm+PubwnLet3H3duB/UBFH8f2VecRBK2fFWb2BzOb21tQZnZluM+K2trUfzO+q4usOIXfg+mptCCbLy+ey19q9vDE68OSR0VE+pVMgpnj7l8HGtz9TuAC4NRowxqUXKDZ3RcRLG/TayvL3W9z90XuvqiysjLlQRy8XHJ0LRiAj582g9njC7np4TW0dXRGei4RkcFIJsF0rRO/z8yOAUqBZMY3thKMiXSZFpb1uo+ZZYV17+nj2L7q3ALcH27/DjguiRhTrutiY1G2YCD4dv//ef9RrK9t4K7nNkZ6LhGRwUgmwdxmZuXA14Bq4DWCwfj+PA/MNbNZZpZDMGhf3WOfauCycPti4AkPBhWqgaXhLLNZwFxgeT91/g/w7nD7bOCNJGJMufrmdvKyM8jNyoz8XIuPmsCZc8dzy6NvsDPWHPn5REQGot8E4+7/7e517v6Mu8929wnAH5I4rh24GngEWAPc5+6rzexGM7sw3O12oMLMaoBrgGvDY1cD9xEksz8CV7l7R6I6w7q+CXzEzF4F/h34TJKvQUqleqHLvpgZ37joGFo7OrmhenX/B4iIpFGf/ThmdjrBIPoz7r7LzI4jSAJncmhXVa/c/WHg4R5l18dtNwMfTXDsTcBNydQZlu8jGB8aVqle6LI/MyoK+dLiuXzrkbU89tpOzlkwMW3nFhHpS8IWjJl9i2Cg/CPAQ2b2DeBPwDKCLivpRRQLXfbns2fOZt7EIq5/YBUHWnQlBRE5PPTVRXYBsNDdLwXeR7CK8mnu/r2w5SG9iEWw0GV/crIy+PcPH8eOWDM3PqiuMhE5PPSVYJq7Eom71wHr3P2ttEQ1gtU3tUU+g6w3J80o5/PvOoL7VmzhkdU70n5+EZGe+nonnG1m8bO+ZsXfd/cLezlmzBuOLrIuX148j6ffqOW6+19lYVUZE4q1JqmIDJ++EkzPZV2+HWUgo0UwyD88CSYnK4PvXnICF3z/Wf7p1yv52adOJiPDhiUWEZG+Frt8Op2BjAbNbR20dnRGttBlMuZMKOZrFxzF1x9Yza1P1vDFxZqPISLDQ1emTKF0LHSZjI+fNoMlJ0zhO4+9wZ/XpX69NRGRZCjBpFA6FrpMhpnx7x8+lrkTivjSr15i676mYY1HRMYmJZgUStdCl8koyMnixx8/ibYO53N3vUBjq74fIyLp1W+CMbMHzay6x+0uM/uymWmaUpz65mivZjlQsyuL+O4lJ7Bq237+/t6X6ejUtWNEJH2SacGsBw4QLIH/UyBGcD2YeeF9CXWtpFw6jIP8PZ2zYCLXf2ABj6zeyTf/sGa4wxGRMSSZd8J3uPvJcfcfNLPn3f1kM9PXxuN0dZGla7HLZH36nbPYuKeRn/55A1XjCvjE6TOHOyQRGQOSSTBFZlbl7psAzKwKKAofa40sshGoa5D/cOkii/f1DyxgS10j11evpiQ/myUn9Ly4qIhIaiXTRfYPwLNm9qSZPQX8GfhHMysE7owyuJEm1txGdqaRl334zZ3IzDD+629P5NRZ47jmvlf4k5aTEZGIJXM9mIcJVk/+CvBl4Eh3f8jdG9z9u9GGN7LUN7dRkpeN2eH57fm87Ez++7KTOWZqKVf/8iV9R0ZEIpXsR+2TgKOB44G/MbNPRhfSyBVrah/278D0pyg3izs/fTKzKwv5zJ0reHLtruEOSURGqWSmKd8F/CdwBnByeFsUcVwj0nAudDkQZQU5/PKzpzFnQhFX/mIFf1y1fbhDEpFRKJmP24uABe6uL1H0I9bUdlgO8PdmXGGQZD79s+Vc9cuX+M+PdvChhdOGOywRGUWS6SJbBUyKOpDRoL65fVgXuhyo0vxs7rriVE6ZGQz8//ef16PPESKSKsm8G44HXjOz5UBLV6GuB/N2seY2inNHRgumS2FuFj/79Mn8/b0v842H1rBpbyPXf2ABWZmH30w4ERlZkkkwN0QdxGgRaxpZLZguedmZ3Pq3J/LNP77Obc+sZ2tdE9+/dCGFuSPvuYjI4aPfdxBdFyY5bR2dNLV1jJgxmJ4yMoz/8/6jmF6ez79Wr+YjP/pffvKJk5hRUTjcoYnICJWwH8TMng1/1ptZLO5Wb2ax9IU4MnQvdDkCZpH15ROnz+Rnnz6F7fub+eAPnuXJ1zWNWUQGJ2GCcfczwp/F7l4Sdyt295L0hTgydC10ebh/DyYZZ8+r5MGrz2BaeQGX3/k833tsHZ1aiVlEBiipkVwzyzSzKWZW1XWLOrCR5nC5mmWqVFUU8NvPv4MPnTCVWx57g0/esZydsebhDktERpBkvmj5RWAn8CjwUHj7fcRxjTjdC12O8C6yePk5mXz7b47n3z98LC9srOO87z7Do6/tHO6wRGSESKYF07X+2NHufmx4Oy7qwEaa+u6rWY78LrJ4Zsalp1Tx4BfPYEpZPp/9xQq++rtXaWjRFTJFpG/JJJjNwP6oAxnpRlsXWU9zJhRx/xfewWfPnMXdyzbxvlue0WKZItKnZK9o+ZSZXWdm13Tdog5spOnqIhsNg/yJ5GZl8tULFvDrz51ObnYGn7h9Of/061fY39g23KGJyGEomQSziWD8JQcojrtJnFhzGxkGhTmjN8F0OXnmOB7+0pl84V1HcP9LWznnlqd58JVtWmZGRA7R57uhmWUC89z9Y2mKZ8SKNbVRnJdNRsbheS2YVMvLzuSfz5vP+4+dzL/8diVf/NVL3L1sIzdceDTzJ2kWu4j004Jx9w5ghpnlDKZyMzvPzNaaWY2ZXdvL47lmdm/4+DIzmxn32HVh+VozO3cAdX7fzA4MJt6hGGkLXabKMVNLqb76DL5x0TG8vqOeC77/LDdUr1a3mYgktRbZeuAvZlYNNHQVuvt3+joobP3cCrwX2AI8b2bV7v5a3G5XAHXuPsfMlgI3A5eY2QJgKcFFzqYAj5nZvPCYhHWa2SKgPInnlHIjcaHLVMnMMD5+2gwuOHYy33n0DX7x3FtUv7KNq989h4+dVkVuVuZwhygiwyCZMZg3Cb73ksHAxmBOAWrcfb27twL3AEt67LMEuDPc/g2w2ILrDS8B7nH3FnffANSE9SWsM0xo3wL+OYnYUm6kLnSZSuWFOfzfi47hwS+ewfxJxdz4+9dY/O2nuf/FLXRoJQCRMSeZxS7/bZB1TyWY4txlC3Bqon3cvd3M9gMVYflfexw7NdxOVOfVQLW7bw9yVO/M7ErgSoCqqtQtSBBrbqNqXEHK6hvJjp5Syt2fOZU/r9vNzX98nWvue4XbnlnPP77vSBYfNYG+fj8iMnr0m2DMrJKgVXA0kNdV7u7viTCuATGzKcBHgXf1t6+73wbcBrBo0aKUfawOxmDGZhdZb8yMs+ZVcsac8Tz06na+/ae1fOYXKzhqcglffM8czjt60piZECEyViXTRXY38DowC/g34C3g+SSO2wpMj7s/LSzrdR8zywJKgT19HJuofCEwB6gxs7eAAjOrSSLGlAlmkY3tLrLeZGQYHzx+Co9eczbf/ujxtLR18IW7X+R9332G/3lpK+0dncMdoohEJJkEU+HutwNt7v60u18OJNN6eR6Ya2azwlloS4HqHvtUA5eF2xcDT3jwZYpqYGk4y2wWMBdYnqhOd3/I3Se5+0x3nwk0uvucJGJMiY5Op76lfdR+iz8VsjMz+MhJ03j0mrP5waULyTTjK/e+zOLvPM3P/7JBS8+IjELJfOTumm+63cwuALYB4/o7KBxTuRp4BMgE7nD31WZ2I7DC3auB24G7wtbGXoKEQbjffcBrQDtwVThlmt7qTP7pRuPAKLkWTDpkhi2aC46dzGNrdvKjp9/khgdf49uPvsHSk6fzydNnMl1jWSKjgvX37Wsz+wDwZ4KuqR8AJcC/hQliRFu0aJGvWLFiyPVs3tvImf/xJN+6+Dg+umh6/wfIIV7aVMcdf3mLh1/djrtz7tGT+PQ7Z3HyzHJNCBA5DJnZC+6+qL/9kplF1rU0/37g3UMNbDTqWuiyWF1kg7KwqpwfVJVz3fnz+cVzG/nV8k38YdUO5kwoYunJ0/nwidMYVzio7/qKyDBK5now88zscTNbFd4/zsy+Fn1oI8fBa8FokH8oppTlc+3583nuuvdw80eOpSg3i288tIbT/t/jfPFXL/G/Nbt1ZU2RESSZd8SfAv8E/ATA3Vea2S+Bb0QZ2Egy2pfqT7eCnCwuObmKS06u4vUdMe5Zvpn7X9zCg69sY0ZFAR85cRoXnTCVqgqN1YgczpJJMAXuvrxHX7im/MSpDwf5SzXIn3LzJ5Vww4VHc+358/njqh3c8/wmvvPoG3zn0Tc4aUY5F50whQuOm6IuNJHDUDIJZreZHQE4gJldDGyPNKoRJtakFkzU8rIzuWjhVC5aOJWt+5qofnkbv3tpC19/YDX/9uBrnD2vkguOm8zioyYq0YscJpJJMFcRfPN9vpltBTYAWr4/TlcXWZG+aJkWU8vy+fy7juBzZ89mzfZ6Hnh5K9WvbOPx13eRnWm8c8543n/MZN67YCLlatmIDJtkZpGtB84xs0Igw93rzewrwHcjjm3EiDW1U5SbRaaWPkkrM2PBlBIWTCnhX86bzytb9vGHVTv4w6rt/PNvV5L5O+P02RWce8wkFs+fwJSy/OEOWWRMSfojt7s3xN29BiWYbrHmNkrUehlWGRnGwqpyFobTnVdvi/Hwq9v5w6odfP1/VvF14KjJJbxnfiXvmT+RE6aX6QOBSMQG+66o/8w49c1t+hb/YcTMOGZqKcdMLeWfzj2SN2sbeOL1nTy+Zhc/fno9tz75JuMKc3jXkZW8+8gJvHPOeE0SEInAYBOMvowQJ9bUroUuD1NmxpwJRcyZUMSVZx3B/sY2nl5XyxNrgoRz/4tbMYNjppRy5tzxnDF3PCfNKNdF0kRSIOG7opnV03siMUCd2XFizW1MKsnrf0cZdqUF2Vx4/BQuPH4K7R2drNy6n2fX7ebP62q57Zn1/PCpN8nPzuTU2eM4Y854Tp1VwYIpJepOExmEhAnG3ZO5aqUQJJh5E/VyjTRZmRmcWFXOiVXlfGnxXA60tPPXN/fwbM1unllXyzceWgNAcW4Wi2aWc+rsCk6dNY5jppaSnZnMQuQiY5v6dVKgvrldg/yjQFFuFucsmMg5CyYCsDPWzF/X72HZhr0sW7+HJ9fWAlCQk8lJM8o5bXYFC6vKOH5aGYW5+v2L9KT/iiFy9/BiYxrkH20mluSx5ISpLDkhuFp3bX0LyzfsZdmGPfx1/R6+9chaADIsWHFgYVVZ0CKaUc7MigKtBC1jnhLMEDW0dtDpWuhyLKgszuWC4yZzwXGTAdjX2MpLm/fx0sY6Xty0jwde3sbdyzYBUF6QzcKqck6sKmNhVTnHTCmltEAfQmRs0bviEGmZmLGrrCCHdx85gXcfOQEIrmxas+sAL26q48WNdby0eR9PvL6re/+qcQUcG06fPja8KenIaKYEM0T1upqlhDIzjCMnFXPkpGIuPaUKgP2NbbyyZR+vbt3Pqq37eWXLPh569eBSfvFJ55ipJRw1uYTxRbnD9RREUkoJZogOXmxML6W8XWlBNmfNq+SseZXdZXUNrazatr876azcemjSGV+Uy1GTi5k/qZj5k4Kkc8SEQn03R0YcvSsOkbrIZKDKC3M4c24lZ849mHT2NbayeluM13fU8/r24Oedz22ktb0TgKwM44jKIuZPDlpI8yYUM3diEdPKC/QdHTlsKcEMUffFxtRFJkNQVpDDO+eM551zxneXtXd08taeRl7fEeP17fWs2R5jxVt1PPDytu59crMyOKKyiLkTi5g7oYg5E4qZM6GIGRUF+q6ODDslmCHqHoNRF5mkWFZmRvcyNx847mB5rLmNml0HqNl5gHW76lm368DbEk92pjGjopDZ4wuZVRn+HF/ErPGFjC/K0RRqSQu9Kw5RVxeZvgcj6VKSl929AkG8hpZ23qw9wLqdB3hjVz0bahvYsLuBp9bW0trR2b1fcW4WsyoLmTX+4G32+CJmji/Q37GklBLMEMWa28nLziAnS90RMrwKc7M4bloZx00rO6S8o9PZtq+J9bsb2FB7gA27G1i/u4EXNtZR/co2PG7FwfFFuVSNy2f6uAKqxhUwfVwB08sLqKooYFJJnsZ7ZECUYIYo1tSmAX45rGVmWJAoxhVwdtxsNoDmtg427W1kfdjaeWt3A5vrGnlhYx2/X7mdjs6D2Sc705halt9dV1VX8hlXwPRx+ZTmZ6vrTQ6hBDNEMV0LRkawvOxM5k0s7nWx1raOTrbva2bT3kY21zUGP8PbH1ftYG9D6yH7F+dlMb08SDZTyvKZUhr+LMtjSlk+lUW5ZKgFNKYowQyRFrqU0So7M4OqiqB7rDf1zW1s3tvE5rqDiWfT3kberG3g2XW7aWjt6FGfMbEkL0w+wc/JZflMDRPQ5NJ8SvKy1AoaRfTOOESxpjbKCnQ1RBl7ivOyWTAlmwVTSt72mLsTa25n276m4La/mW37mti+r4lt+5pZsbGOHSu309556CWninKzmFyax6TSPCaW5DGxJJdJJXlMKMljUklQNr4ohyxNwR4RlGCGKNbcTlVF4XCHIXJYMTNK87Mpzc/mqMlvT0AQTD6orW9h2/6mMPk0szVMSDvrW1i3cze1B1oOGQeCYPXq8UW5TCrNY0JxHpNKc5lYnMfEMClNKM6lsjiXcQU56pIbZkowQxQM8utlFBmozAxjUtha6TnluktHp7OnoYWd+1vYGWtmR6yZXeHPnbEWttQ18sLGvdQ1tvVaf0VhDhNKcqksCpJOZXHXdt7B+8W5FOZkqmsuAnpnHAJ3D8ZgNMgvEonMDGNCcdBSOZbShPs1t3VQW9/CjlgztfUth94OBD/XbK9n94GWt3XLAeRnZ1JZnEtFUQ4VhblUFOZQUZTDuMIcxhflHrJdXpCjryUkSQlmCFraO2nt6NRClyLDLC87s3v6dF86O519TW1xyedgQtpV38Lehla27mti5ZZ97G1o7TUZQbByx/iiXMaFiaiiKExKhTmMK8plfGFQVl6YTVn+2E1Ikb4zmtl5wPeATOC/3f2bPR7PBX4BnATsAS5x97fCx64DrgA6gC+5+yN91WlmdwOLgDZgOfB37v72dnMKaaFLkZElI8MYVxi0Ro6c9Pap2fGCq9W2s7shSDx7DrSwp6GVPQcO3d4Qfml1b0MrCfIRRblZlBVkU16QQ1lBNmUFOZTH/ewqLy/ICbYLsynOHfkz6iJLMGaWCdwKvBfYAjxvZtXu/lrcblcAde4+x8yWAjcDl5jZAmApcDQwBXjMzOaFxySq827g4+E+vwQ+A/woqucHWuhSZDQzM0oLsiktyOaIyv737+h09jW2srehld0HWtnT0EJdQyt1jW3UNbayL/xZ19jGpr2N1DW0EgvXMuxNVob1kYwOLSsLE1RpfjZ52YfPZR2ibMGcAtS4+3oAM7sHWALEJ5glwA3h9m+A/7IgZS8B7nH3FmCDmdWE9ZGoTnd/uKtSM1sOTIvqiXWJaaFLEQllZljQVVaUy9yJyR3T3tHJ/qY26hrb2BeXhOKT0b7GVuoaW9m8t5GVW4Kyrss49CYnK6N7Bl9ft3OOmhj5FVWjfGecCmyOu78FODXRPu7ebmb7gYqw/K89jp0abvdZp5llA58AvtxbUGZ2JXAlQFVVVfLPphda6FJEhiIrM6M7KSXL3Wlq6whaRg1BMtrX1Mr+praDt8aD2ztjzbyxs579TW3dq78DPP4PZ4/oBDNcfgg84+5/7u1Bd78NuA1g0aJFCXpMk9PVginNH40vo4gcjsyMgpwsCnKymFqWP6BjOzqd+uY29jW2MWWAxw5GlO+MW4HpcfenhWW97bPFzLKAUoLB/r6OTVinmf0rUAn8XQri75cG+UVkJMnMsHC8Jj2rj0Q5d+55YK6ZzTKzHIJB++oe+1QDl4XbFwNPuLuH5UvNLNfMZgFzCWaGJazTzD4DnAtc6u6JOyhTqPtiYxrkFxF5m8haMOGYytXAIwRTiu9w99VmdiOwwt2rgduBu8JB/L0ECYNwv/sIJgS0A1e5ewdAb3WGp/wxsBF4Lpzad7+73xjV84NgFllOZga5Y3SOu4hIXyIdPAhndj3co+z6uO1m4KMJjr0JuCmZOsPytA+ExJraKNbqryIivdJH7yGIaZkYEZGElGCGQAtdiogkpgQzBPW6mqWISEJKMEMQa27XQpciIgkowQxB0EWmFoyISG+UYIYgpi4yEZGElGAGqbW9k+a2Tg3yi4gkoAQzSPXNWuhSRKQvSjCD1L1Uvxa6FBHplRLMIGmhSxGRvinBDJIWuhQR6ZsSzCDFusdg1EUmItIbJZhBUheZiEjflGAGqasFoy4yEZHeKcEMUn1zOxkGhTmZwx2KiMhhSQlmkGJNwbf4dS0YEZHeKcEMkha6FBHpmxLMIGmhSxGRvinBDFKsWQlGRKQvSjCDVN/crmViRET6oAQzSLGmNi10KSLSByWYQYo1t6uLTESkD0owg9DR6RxoUReZiEhflGAG4UDXQpdqwYiIJKQEMwha6FJEpH9KMIOwv0nrkImI9EcJZhC6F7pUF5mISEJKMINQr8sli4j0SwlmEHQtGBGR/inBDEJMs8hERPqlBDMIXS2YIs0iExFJKNIEY2bnmdlaM6sxs2t7eTzXzO4NH19mZjPjHrsuLF9rZuf2V6eZzQrrqAnrzInqedU3t1Ocm0Vmhq4FIyKSSGQJxswygVuB84EFwKVmtqDHblcAde4+B7gFuDk8dgGwFDgaOA/4oZll9lPnzcAtYV11Yd2RiDW3aYqyiEg/omzBnALUuPt6d28F7gGW9NhnCXBnuP0bYLEFl4hcAtzj7i3uvgGoCevrtc7wmPeEdRDWeVFUTyxY6FLdYyIifYkywUwFNsfd3xKW9bqPu7cD+4GKPo5NVF4B7AvrSHQuAMzsSjNbYWYramtrB/G04PjpZbzryAmDOlZEZKwYcx/D3f024DaARYsW+WDquOrdc1Iak4jIaBRlC2YrMD3u/rSwrNd9zCwLKAX29HFsovI9QFlYR6JziYhIGkWZYJ4H5oazu3IIBu2re+xTDVwWbl8MPOHuHpYvDWeZzQLmAssT1Rke82RYB2GdD0T43EREpB+RdZG5e7uZXQ08AmQCd7j7ajO7EVjh7tXA7cBdZlYD7CVIGIT73Qe8BrQDV7l7B0BvdYan/BfgHjP7BvBSWLeIiAwTCz78j02LFi3yFStWDHcYIiIjipm94O6L+ttP3+QXEZFIKMGIiEgklGBERCQSSjAiIhKJMT3Ib2a1wMZBHj4e2J3CcFJFcQ2M4hoYxTUwozWuGe5e2d9OYzrBDIWZrUhmFkW6Ka6BUVwDo7gGZqzHpS4yERGJhBKMiIhEQglm8G4b7gASUFwDo7gGRnENzJiOS2MwIiISCbVgREQkEkowIiISDXfXbYA34DxgLcGlnK+NoP7pBJcfeA1YDXw5LL+B4Do3L4e398cdc10Yz1rg3P5iBWYBy8Lye4GcJGN7C3g1PP+KsGwc8CiwLvxZHpYb8P3wHCuBE+PquSzcfx1wWVz5SWH9NeGxlkRMR8a9Ji8DMeArw/V6AXcAu4BVcWWRv0aJztFHTN8CXg/P+zugLCyfCTTFvW4/Huy5+3p+/cQW+e8OyA3v14SPz0wirnvjYnoLeDmdrxmJ3xuG9e8r4f9Cqt8cR/uN4DIBbwKzgRzgFWBBis8xuesPASgG3gAWhP90/9jL/gvCOHLDf6Y3wzgTxgrcBywNt38MfD7J2N4Cxvco+w/Cf2jgWuDmcPv9wB/CP/LTgGVxf6jrw5/l4XbXP8TycF8Ljz1/EL+fHcCM4Xq9gLOAEzn0jSny1yjROfqI6X1AVrh9c1xMM+P36/HcBnTuRM8vidcr8t8d8AXCREBwqZB7+4urx+PfBq5P52tG4veGYf37Svi/MNA3v7F+A04HHom7fx1wXcTnfAB4bx//dIfEQHC9nNMTxRr+4ezm4JvLIfv1E8tbvD3BrAUmh9uTgbXh9k+AS3vuB1wK/CSu/Cdh2WTg9bjyQ/ZLMr73AX8Jt4ft9aLHG046XqNE50gUU4/HPgTc3dd+gzl3oueXxOsV+e+u69hwOyvcz/qKK67cgM3A3OF6zcLHut4bhv3vq7ebxmAGbirBH1aXLWFZJMxsJrCQoAkPcLWZrTSzO8ysvJ+YEpVXAPvcvb1HeTIc+JOZvWBmV4ZlE919e7i9A5g4yLimhts9ywdiKfCruPvD/Xp1ScdrlOgcybic4NNql1lm9pKZPW1mZ8bFOtBzD+X/JerfXfcx4eP7w/2TcSaw093XxZWl9TXr8d5wWP59KcEcxsysCPgt8BV3jwE/Ao4ATgC2EzTR0+0Mdz8ROB+4yszOin/Qg483PgxxEV5G+0Lg12HR4fB6vU06XqOBnMPMvkpw5di7w6LtQJW7LwSuAX5pZiVRnLsPh+XvLs6lHPpBJq2vWS/vDYOuazCSPYcSzMBtJRho6zItLEspM8sm+AO6293vB3D3ne7e4e6dwE+BU/qJKVH5HqDMzLJ6lPfL3beGP3cRDAyfAuw0s8lh3JMJBkYHE9fWcLtnebLOB150951hjMP+esVJx2uU6BwJmdmngA8AHwvfNHD3FnffE26/QDC2MW+Q5x7U/0uafnfdx4SPl4b79ync98MEA/5d8abtNevtvWEQdaXl70sJZuCeB+aa2azwE/NSoDqVJzAzA24H1rj7d+LKJ8ft9iFgVbhdDSw1s1wzmwXMJRio6zXW8I3kSeDi8PjLCPpy+4ur0MyKu7YJxjtWhee/rJe6qoFPWuA0YH/YxH4EeJ+ZlYddH+8j6BffDsTM7LTwNfhkMnHFOeRT5XC/Xj2k4zVKdI5emdl5wD8DF7p7Y1x5pZllhtuzw9dn/SDPnej59SlNv7v4mC8GnuhKsv04h2CcorsrKV2vWaL3hkHUFfnfF6BB/sHcCGZmvEHwKeWrEdR/BkHzcyVx0zSBuwimD64Mf9mT4475ahjPWuJmXiWKlWC2zXKCqYi/BnKTiGs2weycVwimSH41LK8AHieYvvgYMC4sN+DW8NyvAovi6ro8PHcN8Om48kUEbyZvAv9FEtOUw+MKCT59lsaVDcvrRZDktgNtBH3YV6TjNUp0jj5iqiHoh+/6G+uaUfWR8Pf7MvAi8MHBnruv59dPbJH/7oC88H5N+Pjs/uIKy38OfK7Hvml5zUj83jCsf1+JbloqRkREIqEuMhERiYQSjIiIREIJRkREIqEEIyIikVCCERGRSCjBiAyQmVWY2cvhbYeZbY27n9PPsYvM7PsDPN/lZvaqBcumrDKzJWH5p8xsylCei0iUNE1ZZAjM7AbggLv/Z1xZlh9c+2qo9U8DniZYQXd/uERIpbtvMLOnCBaEXJGKc4mkmlowIilgZj83sx+b2TLgP8zsFDN7zoLFD//XzI4M93uXmf0+3L7BgoUcnzKz9Wb2pV6qngDUAwcA3P1AmFwuJvhC3N1hyynfzE6yYKHFF8zsETu4rMdTZva9cL9VZnZKL+cRSTklGJHUmQa8w92vIbiQ15keLH54PfD/EhwzHziXYK2tf7Vgnal4rwA7gQ1m9jMz+yCAu/8GWEGwhtgJBItV/gC42N1PIrhY1k1x9RSE+30hfEwkcln97yIiSfq1u3eE26XAnWY2l2Bpj56Jo8tD7t4CtJjZLoIl0LvXuHL3jnDNsJOBxcAtZnaSu9/Qo54jgWOAR4MlpMgkWOaky6/C+p4xsxIzK3P3fYN/qiL9U4IRSZ2GuO3/Czzp7h+y4LodTyU4piVuu4Ne/ic9GChdDiw3s0eBnxFckCueAavd/fQE5+k52KrBV4mcushEolHKwWXOPzXYSsxsipmdGFd0ArAx3K4nuGwuBAs/VprZ6eFx2WZ2dNxxl4TlZxCsqLt/sDGJJEstGJFo/AdBF9nXgIeGUE828J/hdORmoBb4XPjYz4Efm1kTwaWALwa+b2alBP/b3yVY4Reg2cxeCuu7fAjxiCRN05RFRjlNZ5bhoi4yERGJhFowIiISCbVgREQkEkowIiISCSUYERGJhBKMiIhEQglGREQi8f8BqGCevVtNZCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "9b313778",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "c5930ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "181/181 [==============================] - 14s 34ms/step - loss: 4.6549 - accuracy: 0.0771\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 4.0386 - accuracy: 0.2037\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 3.4020 - accuracy: 0.2093\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.8740 - accuracy: 0.2110\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2.5958 - accuracy: 0.2170\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2.4507 - accuracy: 0.2258\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 2.3400 - accuracy: 0.2316\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2.2383 - accuracy: 0.2380\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2.1382 - accuracy: 0.2447\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 2.0320 - accuracy: 0.2539\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 1.9239 - accuracy: 0.2648\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.8060 - accuracy: 0.2789\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.6845 - accuracy: 0.2945\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.5557 - accuracy: 0.3100\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.4206 - accuracy: 0.3268\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 1.2840 - accuracy: 0.3449\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.1440 - accuracy: 0.3637\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 1.0030 - accuracy: 0.3843\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.8649 - accuracy: 0.4054\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 6s 34ms/step - loss: 0.7323 - accuracy: 0.4263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c77505ab4f0>"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535f5c8",
   "metadata": {},
   "source": [
    "- MAX_LENGTH = 10\n",
    "- NUM_LAYERS = 6 \n",
    "- D_MODEL = 512\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- accuracy: 0.4233\n",
    "-------------------------------\n",
    "- MAX_LENGTH = 20\n",
    "- NUM_LAYERS = 6 \n",
    "- D_MODEL = 512\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- accuracy: 0.2369\n",
    "------------------------------\n",
    "- MAX_LENGTH = 10\n",
    "- NUM_LAYERS = 6 \n",
    "- D_MODEL = 256\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- accuracy: 0.4008\n",
    "------------------------------\n",
    "- MAX_LENGTH = 15\n",
    "- NUM_LAYERS = 6 \n",
    "- D_MODEL = 256\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- accuracy: 0.3261\n",
    "------------------------------\n",
    "- MAX_LENGTH = 10\n",
    "- NUM_LAYERS = 2 \n",
    "- D_MODEL = 256\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- accuracy: 0.5249\n",
    "------------------------------\n",
    "- MAX_LENGTH = 10\n",
    "- NUM_LAYERS = 2 \n",
    "- D_MODEL = 256\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.1\n",
    "- EPOCHS = 20일 때 \n",
    "- warmup_steps=8000으로 늘려봄\n",
    "- accuracy: 0.4263\n",
    "------------------------------\n",
    "- MAX_LENGTH = 10\n",
    "- NUM_LAYERS = 2 \n",
    "- D_MODEL = 256\n",
    "- NUM_HEADS = 8\n",
    "- UNITS = 512\n",
    "- DROPOUT = 0.3\n",
    "- EPOCHS = 20일 때 \n",
    "- warmup_steps=8000\n",
    "- accuracy: 0.3203\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "e6a9879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "        \n",
    "        return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "672c5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "f851cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕\n",
      "출력 : 안녕하세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "48b13fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 반가워\n",
      "출력 : 저도 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 '"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('반가워')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "1dc64a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 챗봇이지\n",
      "출력 : 저를 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저를 '"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너 챗봇이지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "48676201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨 어때요?\n",
      "출력 : 썸 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'썸 '"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 날씨 어때요?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a3e43",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 어렵다.\n",
    "- NLP택해서 더 배워야겠다.\n",
    "- 왜 이리 멍청하지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
